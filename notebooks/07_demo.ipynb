{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07 - Interactive Demo Interface\n",
    "\n",
    "This notebook creates an interactive demo interface using Gradio for showcasing the fine-tuned BRD extraction model.\n",
    "\n",
    "## What we'll do:\n",
    "1. Load the fine-tuned model and extractor\n",
    "2. Create Gradio interface\n",
    "3. Add sample BRDs for testing\n",
    "4. Launch interactive demo\n",
    "5. Optional: Deploy to Hugging Face Spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "from pydantic import ValidationError\n",
    "import json\n",
    "import sys\n",
    "sys.path.append('../data/processed')\n",
    "from brd_extractor import BRDExtractor, ProjectEstimation\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úì Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Model and Initialize Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODEL_ID = \"meta-llama/Llama-3.2-1B\"\n",
    "FINETUNED_MODEL_DIR = \"../models/final/llama-3.2-1b-brd-final\"\n",
    "\n",
    "print(\"Loading model for demo...\\n\")\n",
    "\n",
    "# Quantization config\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    llm_int8_threshold=6.0,\n",
    ")\n",
    "\n",
    "# Load model\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL_ID,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    low_cpu_mem_usage=True,\n",
    ")\n",
    "model = PeftModel.from_pretrained(base_model, FINETUNED_MODEL_DIR)\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_ID)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Initialize extractor\n",
    "extractor = BRDExtractor(model, tokenizer)\n",
    "\n",
    "print(\"‚úì Model loaded and ready for demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Sample BRDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_BRDS = {\n",
    "    \"E-commerce Mobile App\": \"\"\"Business Requirements Document\n",
    "Project: E-commerce Mobile Application\n",
    "\n",
    "Overview:\n",
    "We require a cross-platform mobile application (iOS and Android) for our e-commerce business. \n",
    "The app will feature product browsing, shopping cart functionality, secure checkout, \n",
    "order tracking, and user account management.\n",
    "\n",
    "Technical Scope:\n",
    "- React Native development\n",
    "- Integration with existing REST API\n",
    "- Payment gateway integration (Stripe)\n",
    "- Push notifications\n",
    "- Analytics integration\n",
    "\n",
    "Resource Requirements:\n",
    "- 2 senior mobile developers\n",
    "- 1 UI/UX designer\n",
    "- 1 QA engineer\n",
    "\n",
    "Timeline: \n",
    "The project is estimated to take 16 weeks from kickoff to production deployment.\n",
    "\n",
    "Effort Estimation:\n",
    "Total development effort is estimated at 960 hours across all team members.\n",
    "\n",
    "Budget:\n",
    "The total project cost is projected at $120,000, including all development, \n",
    "design, testing, and deployment activities.\"\"\",\n",
    "    \n",
    "    \"CRM System\": \"\"\"Business Requirements Document\n",
    "Project: Customer Relationship Management System\n",
    "\n",
    "We need a comprehensive CRM system to manage our sales pipeline, customer interactions, \n",
    "and reporting. The system should include lead management, opportunity tracking, \n",
    "email integration, and dashboard analytics.\n",
    "\n",
    "The development team will consist of 3 full-stack developers and 1 business analyst.\n",
    "Project duration is estimated at 12 weeks with a total effort of 720 hours.\n",
    "Budget allocation is $90,000 for the complete solution.\"\"\",\n",
    "    \n",
    "    \"Website Redesign\": \"\"\"Business Requirements Document\n",
    "Project: Corporate Website Redesign\n",
    "\n",
    "Objective: Complete redesign of our corporate website with modern UI/UX, \n",
    "improved performance, and integrated CMS for content management.\n",
    "\n",
    "Key deliverables include:\n",
    "- Responsive design for all devices\n",
    "- WordPress CMS integration\n",
    "- SEO optimization\n",
    "- Contact forms and lead capture\n",
    "- Blog functionality\n",
    "\n",
    "Team: 2 frontend developers, 1 backend developer, 1 designer\n",
    "Timeline: 10 weeks\n",
    "Estimated hours: 600 hours total\n",
    "Project cost: $75,000\"\"\",\n",
    "    \n",
    "    \"API Development\": \"\"\"Business Requirements Document\n",
    "Project: RESTful API Development for Healthcare System\n",
    "\n",
    "We need to develop a secure RESTful API to connect our healthcare management system \n",
    "with third-party applications. The API must be HIPAA compliant and include \n",
    "authentication, rate limiting, and comprehensive documentation.\n",
    "\n",
    "Features:\n",
    "- Patient data endpoints\n",
    "- Appointment scheduling\n",
    "- Medical records access\n",
    "- OAuth 2.0 authentication\n",
    "- API documentation (Swagger)\n",
    "\n",
    "Resources: 2 backend developers, 1 security specialist\n",
    "Duration: 8 weeks\n",
    "Effort: 480 hours\n",
    "Budget: $60,000\"\"\",\n",
    "    \n",
    "    \"Data Pipeline\": \"\"\"Business Requirements Document\n",
    "Project: ETL Data Pipeline Implementation\n",
    "\n",
    "Build a robust data pipeline to extract data from multiple sources (databases, APIs, files), \n",
    "transform it according to business rules, and load it into our data warehouse for analytics.\n",
    "\n",
    "Technical Requirements:\n",
    "- Apache Airflow orchestration\n",
    "- Data validation and quality checks\n",
    "- Error handling and logging\n",
    "- Automated testing\n",
    "- Monitoring and alerts\n",
    "\n",
    "Team composition: 2 data engineers, 1 DevOps engineer\n",
    "Project timeline: 14 weeks\n",
    "Total effort: 840 hours\n",
    "Total cost: $105,000\"\"\"\n",
    "}\n",
    "\n",
    "print(f\"‚úì Loaded {len(SAMPLE_BRDS)} sample BRDs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Demo Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_brd(brd_text: str) -> tuple:\n",
    "    \"\"\"\n",
    "    Extract project estimation from BRD text.\n",
    "    Returns formatted JSON and status message.\n",
    "    \"\"\"\n",
    "    if not brd_text.strip():\n",
    "        return \"Please enter a BRD document.\", \"\"\n",
    "    \n",
    "    try:\n",
    "        # Extract using the model\n",
    "        result = extractor.extract(brd_text, validate=True)\n",
    "        \n",
    "        if result[\"success\"] and result[\"validated\"]:\n",
    "            # Format output\n",
    "            data = result[\"data\"]\n",
    "            formatted_output = f\"\"\"‚úì Extraction Successful!\n",
    "\n",
    "Effort Hours:    {data['effort_hours']:,.1f}\n",
    "Timeline (Weeks): {data['timeline_weeks']}\n",
    "Cost (USD):      ${data['cost_usd']:,.2f}\n",
    "\n",
    "JSON Output:\n",
    "{json.dumps(data, indent=2)}\n",
    "\"\"\"\n",
    "            status = \"‚úì Valid and Validated\"\n",
    "            return formatted_output, status\n",
    "        \n",
    "        elif result[\"success\"] and not result[\"validated\"]:\n",
    "            formatted_output = f\"\"\"‚ö† Extraction successful but validation failed.\n",
    "\n",
    "Extracted Data:\n",
    "{json.dumps(result['data'], indent=2)}\n",
    "\n",
    "Validation Errors:\n",
    "{chr(10).join(result['errors'])}\n",
    "\"\"\"\n",
    "            status = \"‚ö† Needs Validation Review\"\n",
    "            return formatted_output, status\n",
    "        \n",
    "        else:\n",
    "            formatted_output = f\"\"\"‚úó Extraction Failed\n",
    "\n",
    "Errors:\n",
    "{chr(10).join(result['errors'])}\n",
    "\n",
    "Raw Model Output:\n",
    "{result['raw_output']}\n",
    "\"\"\"\n",
    "            status = \"‚úó Extraction Failed\"\n",
    "            return formatted_output, status\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\", \"‚úó Error Occurred\"\n",
    "\n",
    "def load_sample(sample_name: str) -> str:\n",
    "    \"\"\"Load a sample BRD.\"\"\"\n",
    "    return SAMPLE_BRDS.get(sample_name, \"\")\n",
    "\n",
    "print(\"‚úì Demo functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Gradio interface\n",
    "with gr.Blocks(title=\"BRD Project Estimation Extractor\", theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\n",
    "        \"\"\"\n",
    "        # üìä BRD Project Estimation Extractor\n",
    "        \n",
    "        Extract structured project estimations from Business Requirements Documents using a \n",
    "        fine-tuned Llama 3.2 1B model with Pydantic validation.\n",
    "        \n",
    "        ### What it extracts:\n",
    "        - **Effort Hours**: Total project effort\n",
    "        - **Timeline (Weeks)**: Project duration\n",
    "        - **Cost (USD)**: Budget estimate\n",
    "        \n",
    "        ### How it works:\n",
    "        1. Paste your BRD document (or select a sample)\n",
    "        2. Click \"Extract Estimation\"\n",
    "        3. Get validated JSON output\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):\n",
    "            gr.Markdown(\"### üìù Input BRD\")\n",
    "            \n",
    "            # Sample selector\n",
    "            sample_dropdown = gr.Dropdown(\n",
    "                choices=list(SAMPLE_BRDS.keys()),\n",
    "                label=\"Load Sample BRD\",\n",
    "                value=None\n",
    "            )\n",
    "            \n",
    "            # Input text area\n",
    "            input_text = gr.Textbox(\n",
    "                label=\"Business Requirements Document\",\n",
    "                placeholder=\"Paste your BRD document here...\",\n",
    "                lines=15,\n",
    "                max_lines=25\n",
    "            )\n",
    "            \n",
    "            # Extract button\n",
    "            extract_btn = gr.Button(\"üöÄ Extract Estimation\", variant=\"primary\", size=\"lg\")\n",
    "        \n",
    "        with gr.Column(scale=1):\n",
    "            gr.Markdown(\"### üìä Extracted Estimation\")\n",
    "            \n",
    "            # Status\n",
    "            status_text = gr.Textbox(\n",
    "                label=\"Status\",\n",
    "                interactive=False,\n",
    "                lines=1\n",
    "            )\n",
    "            \n",
    "            # Output text area\n",
    "            output_text = gr.Textbox(\n",
    "                label=\"Results\",\n",
    "                placeholder=\"Extracted estimation will appear here...\",\n",
    "                lines=15,\n",
    "                max_lines=25,\n",
    "                interactive=False\n",
    "            )\n",
    "    \n",
    "    # Info section\n",
    "    gr.Markdown(\n",
    "        \"\"\"\n",
    "        ---\n",
    "        ### üî¨ Technical Details\n",
    "        - **Model**: Llama 3.2 1B (Fine-tuned with QLoRA)\n",
    "        - **Training**: 8-bit quantization on CPU\n",
    "        - **Validation**: Pydantic schema with custom validators\n",
    "        - **Techniques**: Low-Rank Adaptation (LoRA), Gradient Checkpointing\n",
    "        \n",
    "        ### üìñ About\n",
    "        This is a demonstration of state-of-the-art fine-tuning techniques for structured \n",
    "        data extraction. The model was trained on 1,000+ synthetic BRD documents using \n",
    "        QLoRA for parameter-efficient fine-tuning.\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    # Event handlers\n",
    "    sample_dropdown.change(\n",
    "        fn=load_sample,\n",
    "        inputs=[sample_dropdown],\n",
    "        outputs=[input_text]\n",
    "    )\n",
    "    \n",
    "    extract_btn.click(\n",
    "        fn=extract_from_brd,\n",
    "        inputs=[input_text],\n",
    "        outputs=[output_text, status_text]\n",
    "    )\n",
    "\n",
    "print(\"‚úì Gradio interface created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Launch Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the demo\n",
    "print(\"Launching demo...\\n\")\n",
    "\n",
    "demo.launch(\n",
    "    share=False,  # Set to True to create public link\n",
    "    server_port=7860,\n",
    "    server_name=\"127.0.0.1\",\n",
    "    show_error=True,\n",
    "    quiet=False\n",
    ")\n",
    "\n",
    "print(\"\\n‚úì Demo is running!\")\n",
    "print(\"  Open your browser to: http://127.0.0.1:7860\")\n",
    "print(\"  Press Ctrl+C to stop the demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Optional: Export Demo for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create standalone app file for deployment\n",
    "app_code = '''\"\"\"Standalone Gradio App for BRD Extraction\n",
    "\n",
    "Run with: python app.py\n",
    "\"\"\"\n",
    "\n",
    "import gradio as gr\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "import json\n",
    "from brd_extractor import BRDExtractor\n",
    "\n",
    "# Load model\n",
    "print(\"Loading model...\")\n",
    "quantization_config = BitsAndBytesConfig(load_in_8bit=True, llm_int8_threshold=6.0)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"meta-llama/Llama-3.2-1B\",\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "model = PeftModel.from_pretrained(base_model, \"./models/final/llama-3.2-1b-brd-final\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "extractor = BRDExtractor(model, tokenizer)\n",
    "print(\"Model loaded!\")\n",
    "\n",
    "def extract_from_brd(brd_text):\n",
    "    if not brd_text.strip():\n",
    "        return \"Please enter a BRD document.\", \"\"\n",
    "    result = extractor.extract(brd_text, validate=True)\n",
    "    if result[\"success\"] and result[\"validated\"]:\n",
    "        data = result[\"data\"]\n",
    "        output = f'''‚úì Extraction Successful!\n",
    "\n",
    "Effort Hours:     {data['effort_hours']:,.1f}\n",
    "Timeline (Weeks): {data['timeline_weeks']}\n",
    "Cost (USD):       ${data['cost_usd']:,.2f}\n",
    "\n",
    "JSON Output:\n",
    "{json.dumps(data, indent=2)}'''\n",
    "        return output, \"‚úì Valid and Validated\"\n",
    "    return \"Extraction failed\", \"‚úó Failed\"\n",
    "\n",
    "# Create interface\n",
    "with gr.Blocks(title=\"BRD Extractor\", theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\"# BRD Project Estimation Extractor\")\n",
    "    with gr.Row():\n",
    "        input_text = gr.Textbox(label=\"BRD Document\", lines=10)\n",
    "        output_text = gr.Textbox(label=\"Results\", lines=10)\n",
    "    status = gr.Textbox(label=\"Status\")\n",
    "    btn = gr.Button(\"Extract\")\n",
    "    btn.click(extract_from_brd, inputs=[input_text], outputs=[output_text, status])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()\n",
    "'''\n",
    "\n",
    "with open(\"../app.py\", \"w\") as f:\n",
    "    f.write(app_code)\n",
    "\n",
    "print(\"‚úì Standalone app saved to: ../app.py\")\n",
    "print(\"\\nTo run: python app.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What we've built:\n",
    "- ‚úì Interactive Gradio demo interface\n",
    "- ‚úì Sample BRDs for testing\n",
    "- ‚úì Real-time extraction with validation\n",
    "- ‚úì User-friendly UI with status indicators\n",
    "- ‚úì Standalone app for deployment\n",
    "\n",
    "### Features:\n",
    "- **Sample BRDs**: Pre-loaded examples for quick testing\n",
    "- **Real-time Extraction**: Immediate results\n",
    "- **Validation Status**: Clear feedback on data quality\n",
    "- **JSON Output**: Structured, validated data\n",
    "- **Error Handling**: Graceful failure messages\n",
    "\n",
    "### Deployment Options:\n",
    "1. **Local**: Run on localhost (current setup)\n",
    "2. **Hugging Face Spaces**: Deploy with `demo.launch(share=True)`\n",
    "3. **Docker**: Containerize the app\n",
    "4. **Cloud**: Deploy to AWS/GCP/Azure\n",
    "5. **API**: Wrap in FastAPI for REST endpoints\n",
    "\n",
    "### Usage:\n",
    "1. Select a sample BRD or paste your own\n",
    "2. Click \"Extract Estimation\"\n",
    "3. View validated JSON output\n",
    "4. Share with stakeholders!\n",
    "\n",
    "### Next Steps:\n",
    "- Share the demo link with colleagues\n",
    "- Collect feedback on accuracy\n",
    "- Iterate on the model with new data\n",
    "- Deploy to production environment\n",
    "\n",
    "### Files Created:\n",
    "- `app.py`: Standalone Gradio app\n",
    "\n",
    "Congratulations! You've built a complete end-to-end ML project! üéâ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
